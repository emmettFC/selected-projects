{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Data Driven Yale: Analytical regionalization & Social media data\n",
    "        I: Trial 2D PCA & Kmeans clustering of polygon vectors\n",
    "        II: Make signature graphs for each cluster (re FM)\n",
    "'''\n",
    "\n",
    "# -- \n",
    "# dependancies\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geojson\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "from shapely import geometry\n",
    "from shapely.geometry.polygon import LinearRing, Polygon\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from shapely.geometry import shape, Point\n",
    "from descartes import PolygonPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# user defined funtions\n",
    "\n",
    "def fixLstring(row): \n",
    "    v = row['combined']\n",
    "    s = v[1:-1].split(', ')\n",
    "    s = [np.float(i) for i in s]\n",
    "    return s\n",
    "\n",
    "def normVec(row): \n",
    "    v = row['combined']\n",
    "    d = np.sum(v)\n",
    "    norm = [np.float(i)/np.float(d) for i in v]\n",
    "    return norm\n",
    "\n",
    "def getAvgVec(row): \n",
    "    vecs = np.array(row['normalized_vector'])\n",
    "    comb = np.mean(vecs, axis=0)\n",
    "    return comb\n",
    "\n",
    "def coercePolygon(row): \n",
    "    string = row['polygon'].replace('POLYGON ((', ''). replace('))', '')\n",
    "    s = string.split(', ')\n",
    "    s = [i.split(' ') for i in s]\n",
    "    verts = []\n",
    "    for i in s: \n",
    "        vert = [np.float(v) for v in i]\n",
    "        vert = tuple(vert)\n",
    "        verts.append(vert)\n",
    "    return verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# io \n",
    "\n",
    "dhv = pd.read_csv('../data/day-hour-vectors.csv')\n",
    "dhv['combined_list'] = dhv.apply(lambda row: fixLstring(row), axis=1)\n",
    "len(dhv.iloc[0].combined_list) # 168 dim, correct\n",
    "# [ 0.11674758  0.0951933 ]\n",
    "\n",
    "whv = pd.read_csv('../data/weekday-weekend-hour-vectors.csv')\n",
    "whv['combined_list'] = whv.apply(lambda row: fixLstring(row), axis=1)\n",
    "len(whv.iloc[0].combined_list) # 48 dim, correct\n",
    "# [ 0.22319044  0.16556947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# run PCA and kmeans clustering on aggregate vectors\n",
    "\n",
    "cluster_frame_whv = whv[['label', 'combined_list']]\n",
    "cluster_frame_dhv = dhv[['label', 'combined_list']]\n",
    "\n",
    "cluster_frame_whv.columns = ['label', 'combined']\n",
    "cluster_frame_dhv.columns = ['label', 'combined']\n",
    "cluster_frame_whv['normalized_vector'] = cluster_frame_whv.apply(lambda row: normVec(row), axis=1)\n",
    "cluster_frame_dhv['normalized_vector'] = cluster_frame_dhv.apply(lambda row: normVec(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# cluster normalalized vectors \n",
    "\n",
    "cluster_frame_whv.set_index('label', inplace=True)\n",
    "cluster_frame2w = pd.DataFrame(cluster_frame_whv['normalized_vector'].values.tolist())\n",
    "cluster_frame2w.index.names = ['polygon']\n",
    "cluster_frame2w.columns.names = ['time_slot']\n",
    "\n",
    "cluster_frame_dhv.set_index('label', inplace=True)\n",
    "cluster_frame2d = pd.DataFrame(cluster_frame_dhv['normalized_vector'].values.tolist())\n",
    "cluster_frame2d.index.names = ['polygon']\n",
    "cluster_frame2d.columns.names = ['time_slot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# PCA whv\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(cluster_frame2w)\n",
    "pca_cluster_2d_w = pca.transform(cluster_frame2w)\n",
    "pca_cluster_df_2d_w = pd.DataFrame(pca_cluster_2d_w)\n",
    "pca_cluster_df_2d_w.index = cluster_frame2w.index\n",
    "pca_cluster_df_2d_w.columns = ['PC1','PC2']\n",
    "\n",
    "'''Look at clustering performance week hour'''\n",
    "print(pca.explained_variance_ratio_) \n",
    "# [ 0.23911869  0.13230798]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# PCA dhv\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(cluster_frame2d)\n",
    "pca_cluster_2d_d = pca.transform(cluster_frame2d)\n",
    "pca_cluster_df_2d_d = pd.DataFrame(pca_cluster_2d_d)\n",
    "pca_cluster_df_2d_d.index = cluster_frame2d.index\n",
    "pca_cluster_df_2d_d.columns = ['PC1','PC2']\n",
    "\n",
    "'''Look at clustering performance week hour'''\n",
    "print(pca.explained_variance_ratio_) \n",
    "# [ 0.12612413  0.07584815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# kmeans n = 3 whv\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit(cluster_frame2w)\n",
    "pca_cluster_df_2d_w['cluster'] = pd.Series(clusters.labels_, index=pca_cluster_df_2d_w.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# kmeans n = 3 dhv\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit(cluster_frame2d)\n",
    "pca_cluster_df_2d_d['cluster'] = pd.Series(clusters.labels_, index=pca_cluster_df_2d_d.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# plot result of preliminary clustering / dim reduction\n",
    "\n",
    "'''Add color dictionary to centroids: 3 cluster'''\n",
    "colors = ['yellow', 'red', 'orange']\n",
    "clrs = []\n",
    "for i in range(len(colors)): \n",
    "    out = {\n",
    "        'color' : colors[i],\n",
    "        'cluster' : i\n",
    "    }\n",
    "    clrs.append(out)\n",
    "\n",
    "df_color = pd.DataFrame(clrs)\n",
    "df_2d_pca_48 = pd.merge(pca_cluster_df_2d_w, df_color, on='cluster', how='left')\n",
    "df_2d_pca_168 = pd.merge(pca_cluster_df_2d_d, df_color, on='cluster', how='left')\n",
    "\n",
    "'''Look at plot of clusters: (Not great but move on / compare to denormalized plot'''\n",
    "# df_2d_pca_48.plot(kind='scatter', x='PC2', y='PC1', c=df_2d_pca_48.color, figsize=(16,8))\n",
    "# df_2d_pca_168.plot(kind='scatter', x='PC2', y='PC1', c=df_2d_pca_168.color, figsize=(16,8))\n",
    "# week hour looks much better than day hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# Join cluster id back to dataframe on polygon label: this is a unique id for vectors\n",
    "\n",
    "df_2d_pca_48.reset_index(inplace=True)\n",
    "df_2d_pca_48.columns = ['label', 'PC1', 'PC2', 'cluster', 'color']\n",
    "df_plotw = pd.merge(df_2d_pca_48, cluster_frame_whv, on='label', how='left')\n",
    "df_plot_groupedw = df_plotw.groupby('cluster').agg({'normalized_vector':(lambda x: list(x))})\n",
    "df_plot_groupedw.reset_index(inplace=True)\n",
    "\n",
    "df_2d_pca_168.reset_index(inplace=True)\n",
    "df_2d_pca_168.columns = ['label', 'PC1', 'PC2', 'cluster', 'color']\n",
    "df_plotd = pd.merge(df_2d_pca_168, cluster_frame_dhv, on='label', how='left')\n",
    "df_plot_groupedd = df_plotd.groupby('cluster').agg({'normalized_vector':(lambda x: list(x))})\n",
    "df_plot_groupedd.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# Agregate average vectors from aggregates based on cluster-label assignment\n",
    "\n",
    "df_plot_groupedw['avg_vec'] = df_plot_groupedw.apply(lambda row: getAvgVec(row), axis=1)\n",
    "df_plot_groupedw = df_plot_groupedw[['cluster', 'avg_vec']]\n",
    "\n",
    "df_plot_groupedd['avg_vec'] = df_plot_groupedd.apply(lambda row: getAvgVec(row), axis=1)\n",
    "df_plot_groupedd = df_plot_groupedd[['cluster', 'avg_vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# Plot spectral signature graphs day hours \n",
    "'''tab in one of below commands depnding on vector aggregation level'''\n",
    "df_plot_grouped = df_plot_groupedd\n",
    "# df_plot_grouped = df_plot_groupedw\n",
    "'''Plot all clusters (replicate Frias-Martinez signature graphs)'''\n",
    "x = np.array(df_plot_grouped.iloc[0]['avg_vec'])\n",
    "ind = len(df_plot_grouped.iloc[0].avg_vec)\n",
    "y = range(ind)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line = ind / 2\n",
    "\n",
    "'''PLotting for three clusters'''\n",
    "x1 = np.array(df_plot_grouped.iloc[1]['avg_vec'])\n",
    "x2 = np.array(df_plot_grouped.iloc[2]['avg_vec'])\n",
    "\n",
    "'''Plotting for three clusters'''\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(y, x)\n",
    "plt.axvline(x=line, color='blue')\n",
    "plt.title('Spectral Graphs: Naive Kmeans')\n",
    "plt.ylabel('Cluster 0')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(y, x1)\n",
    "plt.axvline(x=line, color='blue')\n",
    "plt.ylabel('Cluster 1')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(y, x2)\n",
    "plt.axvline(x=line, color='blue')\n",
    "plt.ylabel('Cluster 2')\n",
    "\n",
    "if ind in (48, 168):\n",
    "    unit = 'hour' \n",
    "elif ind in (144, 504): \n",
    "    unit = 'segment'\n",
    "\n",
    "plt.xlabel(str(ind) + ' Component Period (' + unit + ')')\n",
    "\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "\n",
    "path = './plots/cluster-all-test-' + str(ind) + '-' + unit + '-split-line.png'\n",
    "# plt.savefig(path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# make polygon frame to prepare for geoplot\n",
    "\n",
    "polys = whv.groupby('label').agg({'polygon' : 'max'})\n",
    "polys.reset_index(inplace=True)\n",
    "polys['pgon'] = polys.apply(lambda row: coercePolygon(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# join to whv and dhv frames\n",
    "\n",
    "df_plot_polyw = pd.merge(df_2d_pca_48, polys, on='label', how='left')\n",
    "df_plot_polyw.reset_index(inplace=True)\n",
    "\n",
    "df_plot_polyd = pd.merge(df_2d_pca_168, polys, on='label', how='left')\n",
    "df_plot_polyd.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# load base geojson file to plot polygon cluster assignment\n",
    "\n",
    "with open(\"../data/beijing.geojson\") as json_file:\n",
    "    json_data = geojson.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- \n",
    "# plot polygons with cluster assignment\n",
    "\n",
    "'''Plot geojson polygons'''\n",
    "fig = plt.figure() \n",
    "feats = json_data['features']\n",
    "for i in range(0, len(feats)): \n",
    "    try: \n",
    "        test = feats[i]\n",
    "        poly = test['geometry']\n",
    "        coords = poly['coordinates']\n",
    "        x = [i for i,j in coords[0]]\n",
    "        y = [j for i,j in coords[0]]\n",
    "        ax = fig.gca() \n",
    "        # ax.plot(x,y)\n",
    "        ax.plot(x, y, color='black')\n",
    "        ax.axis('scaled')\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "\n",
    "'''Demo plot polygon with color fill: tab in depending on aggregation level'''\n",
    "# df_plot_poly = df_plot_polyw\n",
    "df_plot_poly = df_plot_polyd\n",
    "\n",
    "for i in range(len(polys)): \n",
    "    verts = df_plot_poly.iloc[i]['pgon']\n",
    "    color = df_plot_poly.iloc[i]['color']\n",
    "    pList = [Point(i) for i in verts]\n",
    "    poly = geometry.Polygon([[p.x, p.y] for p in pList])\n",
    "    x,y = poly.exterior.xy\n",
    "    ax.plot(x, y, color='black', alpha=0.7,# color='#6699cc', alpha=0.7,\n",
    "        linewidth=1.25, solid_capstyle='round', zorder=2)\n",
    "    ring_mixed = Polygon(verts)\n",
    "    ring_patch = PolygonPatch(ring_mixed, fc=color)\n",
    "    ax.add_patch(ring_patch)\n",
    "\n",
    "'''Limit axis to focus region'''\n",
    "dfWB = pd.read_csv('../data/inLabelRegionPoints.csv')\n",
    "maxLon, minLon = np.max(dfWB['lon']), np.min(dfWB['lon'])\n",
    "maxLat, minLat = np.max(dfWB['lat']), np.min(dfWB['lat'])\n",
    "ax.set_xlim(maxLon, minLon)\n",
    "ax.set_ylim(maxLat, minLat)\n",
    "\n",
    "'''Reveal plot'''\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
