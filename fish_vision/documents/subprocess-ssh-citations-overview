
# This file is a placeholder, as both of my sensors are in the Bioengineering Lab at Penn where I am working on them.
    The hot-glue seam on one of the camera sensors broke and some of the equiptment got destroyed. The sd card with the 
    linux image is fine, but the board itself needs to be replaced. The openCv implementation script is on the sd, so I 
    do not have access at the moment. 

I: Description of the code: 
    The openCv motion detection scripts in this directory are nearly identical to the process I have running on the boards. 
    The only change is that I had to use a sub-process to write out tagged frames to the usb storage device I have in 
    one of the ports on the Pi. This subprocess, and the Raspbian configuration I used were based on the following two 
    resources: 

    A) http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1237&context=cpesp
        - This is a very similar project to the one I have done from a hardware perspective, though both my motion detection 
            process and machine-learning (tensorflow) component are completely different. They also took static images at 
            regular intervals as opposed to initializing a camera stream. That said, thier hardware config was much 
            better than mine, and included a ethernet cable /wi-fi module to remotely transmit data. 

    B) https://medium.com/@Cvrsor/how-to-make-a-diy-home-alarm-system-with-a-raspberry-pi-and-a-webcam-2d5a2d61da3d
        - This resource I used only for the set up commands / enabling ssh on the Pi. Though I would like to experiment 
            and compare the efficency of 'motion' - the linux shell program they are using to do detection - and the 
            openCv detection script I used. 

    

